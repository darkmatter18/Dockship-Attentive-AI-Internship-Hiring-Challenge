{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Infarence\n",
    "---\n",
    "\n",
    "The project repo [https://github.com/darkmatter18/Dockship-Attentive-AI-Internship-Hiring-Challenge](https://github.com/darkmatter18/Dockship-Attentive-AI-Internship-Hiring-Challenge)\n",
    "\n",
    "Please refer to this notebook to know, how I get the Normaliation values [https://github.com/darkmatter18/Dockship-Attentive-AI-Internship-Hiring-Challenge/blob/master/Normalize_and-analize.ipynb](https://github.com/darkmatter18/Dockship-Attentive-AI-Internship-Hiring-Challenge/blob/master/Normalize_and-analize.ipynb)\n",
    "\n",
    "- [Hyperparameters](#Hyperparameters)\n",
    "- [Training](#Training)\n",
    "    1. [Torch Dataset and Dataloader](#Torch-Dataset-and-Dataloader)\n",
    "        - [Datasets](#Datasets)\n",
    "        - [Dataloaders](#Dataloaders)\n",
    "    2. [CUDA](#CUDA)\n",
    "    3. [Models](#Models)\n",
    "        1. [Resnet Model](#Resnet-Model)\n",
    "        2. [Densenet Model](#Densenet-Model)\n",
    "    4. [Loss and Optimizer](#Loss-and-Optimizer)\n",
    "    5. [Training](#Training-Loop)\n",
    "    6. [Training Stats](#Training-Stats)\n",
    "- [Testing](#Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_SIZE = 256\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "LR = 1\n",
    "EPOCHS = 50\n",
    "\n",
    "CENTER_CROP_FIVE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>Adhered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>Adhered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>Concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>Concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>Plastic &amp; fabric</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                 1\n",
       "0  0.jpg           Adhered\n",
       "1  1.jpg           Adhered\n",
       "2  2.jpg          Concrete\n",
       "3  3.jpg          Concrete\n",
       "4  4.jpg  Plastic & fabric"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the Datafarme\n",
    "data = pd.read_csv('./dataset/train_challenge.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Classes\n",
    "CLASSES = ['Adhered', 'Ballasted', 'Concrete', 'Plastic & fabric', 'Shingle', 'Steel']\n",
    "\n",
    "classes_to_idx = {cls: idx for idx, cls in enumerate(CLASSES)}\n",
    "idx_to_classes = {idx: cls for idx, cls in enumerate(CLASSES)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1\n",
       "0  0.jpg  0\n",
       "1  1.jpg  0\n",
       "2  2.jpg  2\n",
       "3  3.jpg  2\n",
       "4  4.jpg  3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace '1' column with classes_to_idx dict\n",
    "data = data.replace({'1': classes_to_idx})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make X and Y from dataframe\n",
    "X = data['0'].values\n",
    "Y = data['1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 6915\n",
      "Validation size: 1729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split into train, validation and test sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "print(f\"Train size: {len(X_train)}\\nValidation size: {len(X_val)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteDataset(Dataset):\n",
    "    def __init__(self, dataroot: str, X_array: np.array, Y_array: np.array, transform = None, target_transform = None):\n",
    "        self.dataroot = dataroot\n",
    "        self.X_array = X_array\n",
    "        self.Y_array = Y_array\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_name = self.X_array[index]\n",
    "        img = Image.open(os.path.join(self.dataroot, file_name)).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        label = np.array(self.Y_array[index])\n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "        else:\n",
    "            label = torch.from_numpy(label)\n",
    "\n",
    "        return {'image': img, 'label': label, 'image_name': file_name}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SatelliteDataset(dataroot='./dataset/train/', X_array=X_train, Y_array=y_train, \n",
    "                                 transform=transforms.Compose([transforms.ColorJitter(0.2, 0.2),\n",
    "                                                               transforms.Resize(CROP_SIZE),\n",
    "                                                               transforms.RandomHorizontalFlip(),\n",
    "                                                               transforms.RandomCrop(IMAGE_SIZE),\n",
    "                                                               transforms.ToTensor(),\n",
    "                                                               transforms.Normalize([0.4728, 0.4762, 0.4692],\n",
    "                                                                                    [0.2558, 0.2532, 0.2457]),\n",
    "                                                               transforms.RandomErasing()]))\n",
    "\n",
    "val_dataset = SatelliteDataset(dataroot='./dataset/train/', X_array=X_val, Y_array=y_val, \n",
    "                               transform=transforms.Compose([transforms.Resize(CROP_SIZE),\n",
    "                                                             transforms.CenterCrop(IMAGE_SIZE),\n",
    "                                                             transforms.ToTensor(),\n",
    "                                                             transforms.Normalize([0.4728, 0.4762, 0.4692],\n",
    "                                                                                  [0.2558, 0.2532, 0.2457])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tesla T4 for Training\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Using {torch.cuda.get_device_name()} for Training\")\n",
    "else:\n",
    "    print(\"Using CPU for Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResnetModel, self).__init__()\n",
    "        r = models.resnet18(pretrained=True)\n",
    "        fc = nn.Linear(r.fc.in_features, len(CLASSES))\n",
    "        r.fc = fc\n",
    "        self.model = r\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Densenet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DensenetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DensenetModel, self).__init__()\n",
    "        m = models.densenet161(pretrained=True)\n",
    "        fc = nn.Linear(m.classifier.in_features, len(CLASSES))\n",
    "        m.classifier = fc\n",
    "        self.model = m\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DensenetModel(\n",
       "  (model): DenseNet(\n",
       "    (features): Sequential(\n",
       "      (conv0): Conv2d(3, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (norm0): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu0): ReLU(inplace=True)\n",
       "      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (denseblock1): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(144, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition1): _Transition(\n",
       "        (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock2): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(240, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(336, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition2): _Transition(\n",
       "        (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock3): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(432, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(528, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(528, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(624, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(624, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(720, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(720, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(816, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(816, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(864, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(912, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(912, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer13): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(960, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer14): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1008, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1008, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer15): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer16): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer17): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer18): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer19): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer20): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer21): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer22): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer23): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer24): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer25): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer26): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer27): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer28): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer29): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer30): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer31): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer32): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer33): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer34): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer35): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer36): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition3): _Transition(\n",
       "        (norm): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(2112, 1056, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock4): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1056, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1056, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1104, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1104, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1200, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1248, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1248, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1296, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1296, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1344, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1344, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1392, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1392, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1440, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1488, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1488, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1536, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1584, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1584, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer13): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1632, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer14): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1680, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1680, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer15): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1728, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1728, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer16): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1776, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1776, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer17): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1824, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1824, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer18): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1872, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1872, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer19): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1920, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer20): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(1968, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(1968, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer21): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(2016, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(2016, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer22): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(2064, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(2064, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer23): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(2112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(2112, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer24): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(2160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(2160, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(192, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (norm5): BatchNorm2d(2208, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (classifier): Linear(in_features=2208, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DensenetModel()\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "criterion = nn.NLLLoss().cuda() if torch.cuda.is_available() else nn.NLLLoss()\n",
    "\n",
    "# Optimizer\n",
    "# optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_START = 1e-5\n",
    "LR_MAX = 7e-5 \n",
    "LR_MIN = LR_START\n",
    "LR_RAMPUP_EPOCHS = 7\n",
    "LR_SUSTAIN_EPOCHS = 0 # 3\n",
    "LR_EXP_DECAY = 0.80\n",
    "\n",
    "def lrfn(epoch):\n",
    "    if epoch < LR_RAMPUP_EPOCHS:\n",
    "        lr = LR_START + (epoch * (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS)\n",
    "    elif epoch < (LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS):\n",
    "        lr = LR_MAX\n",
    "    else:\n",
    "        lr = LR_MIN + (LR_MAX - LR_MIN) * LR_EXP_DECAY ** (epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS)\n",
    "#    print('For epoch', epoch, 'setting lr to', lr)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-05.\n"
     ]
    }
   ],
   "source": [
    "scheduler = lr_scheduler.LambdaLR(optimizer, lrfn, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Stated on 2021-02-04 08:33:14\n",
      "Saving model for Epoch 1\n",
      "Saving improved Model for Epoch 1\n",
      "Adjusting learning rate of group 0 to 1.8571e-05.\n",
      "[Epoch: 1/50] Time Taken: 0:07:40 training loss: 1.2013692372360698 validation loss: 0.7364607882368696, accuracy: 0.7674956622325043\n",
      "Saving model for Epoch 2\n",
      "Saving improved Model for Epoch 2\n",
      "Adjusting learning rate of group 0 to 2.7143e-05.\n",
      "[Epoch: 2/50] Time Taken: 0:07:38 training loss: 0.6681859752533665 validation loss: 0.4874737750334334, accuracy: 0.8259109311740891\n",
      "Saving model for Epoch 3\n",
      "Saving improved Model for Epoch 3\n",
      "Adjusting learning rate of group 0 to 3.5714e-05.\n",
      "[Epoch: 3/50] Time Taken: 0:07:37 training loss: 0.5170481585133188 validation loss: 0.4386383631768135, accuracy: 0.8502024291497976\n",
      "Saving model for Epoch 4\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 4.4286e-05.\n",
      "[Epoch: 4/50] Time Taken: 0:07:36 training loss: 0.44004949677361155 validation loss: 0.4301562017985787, accuracy: 0.8455754771544245\n",
      "Saving model for Epoch 5\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 5.2857e-05.\n",
      "[Epoch: 5/50] Time Taken: 0:07:36 training loss: 0.3899884643885681 validation loss: 0.5129996011037156, accuracy: 0.8143435511856565\n",
      "Saving model for Epoch 6\n",
      "Saving improved Model for Epoch 6\n",
      "Adjusting learning rate of group 0 to 6.1429e-05.\n",
      "[Epoch: 6/50] Time Taken: 0:07:29 training loss: 0.35656985064304486 validation loss: 0.41126907664033396, accuracy: 0.8617698091382302\n",
      "Saving model for Epoch 7\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 7.0000e-05.\n",
      "[Epoch: 7/50] Time Taken: 0:07:32 training loss: 0.32786819278892193 validation loss: 0.43196919697058844, accuracy: 0.8519375361480624\n",
      "Saving model for Epoch 8\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 5.8000e-05.\n",
      "[Epoch: 8/50] Time Taken: 0:07:19 training loss: 0.2976758241437952 validation loss: 0.4081916552071474, accuracy: 0.858877964141122\n",
      "Saving model for Epoch 9\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 4.8400e-05.\n",
      "[Epoch: 9/50] Time Taken: 0:07:25 training loss: 0.25051305294036863 validation loss: 0.5044916671937242, accuracy: 0.838635049161365\n",
      "Saving model for Epoch 10\n",
      "Saving improved Model for Epoch 10\n",
      "Adjusting learning rate of group 0 to 4.0720e-05.\n",
      "[Epoch: 10/50] Time Taken: 0:07:37 training loss: 0.20629041658220132 validation loss: 0.36989459620550075, accuracy: 0.8901098901098901\n",
      "Saving model for Epoch 11\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 3.4576e-05.\n",
      "[Epoch: 11/50] Time Taken: 0:07:39 training loss: 0.17291969527219053 validation loss: 0.38715964415045473, accuracy: 0.8837478311162522\n",
      "Saving model for Epoch 12\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 2.9661e-05.\n",
      "[Epoch: 12/50] Time Taken: 0:07:32 training loss: 0.14989667852461036 validation loss: 0.38773808477176036, accuracy: 0.8860613071139387\n",
      "Saving model for Epoch 13\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 2.5729e-05.\n",
      "[Epoch: 13/50] Time Taken: 0:07:27 training loss: 0.12432453124228372 validation loss: 0.36650032974975405, accuracy: 0.8895315211104685\n",
      "Saving model for Epoch 14\n",
      "Saving improved Model for Epoch 14\n",
      "Adjusting learning rate of group 0 to 2.2583e-05.\n",
      "[Epoch: 14/50] Time Taken: 0:07:39 training loss: 0.12485679112649532 validation loss: 0.3718057296466688, accuracy: 0.8999421631000578\n",
      "Saving model for Epoch 15\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 2.0066e-05.\n",
      "[Epoch: 15/50] Time Taken: 0:07:33 training loss: 0.10277324024741406 validation loss: 0.39512142685297613, accuracy: 0.8912666281087334\n",
      "Saving model for Epoch 16\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 1.8053e-05.\n",
      "[Epoch: 16/50] Time Taken: 0:07:36 training loss: 0.09614711146551203 validation loss: 0.3770065653299996, accuracy: 0.891844997108155\n",
      "Saving model for Epoch 17\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 1.6442e-05.\n",
      "[Epoch: 17/50] Time Taken: 0:07:26 training loss: 0.08449002946966037 validation loss: 0.3975695532767082, accuracy: 0.8906882591093117\n",
      "Saving model for Epoch 18\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 1.5154e-05.\n",
      "[Epoch: 18/50] Time Taken: 0:07:26 training loss: 0.07727001379664909 validation loss: 0.38673852150249816, accuracy: 0.896471949103528\n",
      "Saving model for Epoch 19\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 1.4123e-05.\n",
      "[Epoch: 19/50] Time Taken: 0:07:37 training loss: 0.07193581331965722 validation loss: 0.37674250163029105, accuracy: 0.898207056101793\n",
      "Saving model for Epoch 20\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 1.3299e-05.\n",
      "[Epoch: 20/50] Time Taken: 0:07:28 training loss: 0.07399537640900519 validation loss: 0.39091942271437474, accuracy: 0.8987854251012146\n",
      "Saving model for Epoch 21\n",
      "Saving improved Model for Epoch 21\n",
      "Adjusting learning rate of group 0 to 1.2639e-05.\n",
      "[Epoch: 21/50] Time Taken: 0:07:39 training loss: 0.06736539613040715 validation loss: 0.3782148291082151, accuracy: 0.902834008097166\n",
      "Saving model for Epoch 22\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 1.2111e-05.\n",
      "[Epoch: 22/50] Time Taken: 0:07:32 training loss: 0.0597816073304057 validation loss: 0.43474489243452247, accuracy: 0.8947368421052632\n",
      "Saving model for Epoch 23\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 1.1689e-05.\n",
      "[Epoch: 23/50] Time Taken: 0:07:36 training loss: 0.06354865197763009 validation loss: 0.3919022440311901, accuracy: 0.9005205320994795\n",
      "Saving model for Epoch 24\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 1.1351e-05.\n",
      "[Epoch: 24/50] Time Taken: 0:07:37 training loss: 0.06041733950621631 validation loss: 0.39651228913050546, accuracy: 0.9016772700983228\n",
      "Saving model for Epoch 25\n",
      "Saving improved Model for Epoch 25\n",
      "Adjusting learning rate of group 0 to 1.1081e-05.\n",
      "[Epoch: 25/50] Time Taken: 0:07:37 training loss: 0.057720054183976854 validation loss: 0.38214190045943697, accuracy: 0.9063042220936958\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "accuracies = []\n",
    "better_accuracy = 0.0\n",
    "\n",
    "print(f\"Training Stated on {datetime.datetime.now().replace(microsecond=0)}\")\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    a = datetime.datetime.now().replace(microsecond=0)\n",
    "    #Training\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for data in trainloader:\n",
    "        x = data['image'].to(device)\n",
    "        y = data['label'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * x.size(0)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in valloader:\n",
    "            x = data['image'].to(device)\n",
    "            y = data['label'].to(device)\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            test_loss += loss.item() * x.size(0)\n",
    "            accuracy += accuracy_score(y.cpu().numpy(), torch.exp(out).argmax(1).cpu().numpy()) * x.size(0)\n",
    "        \n",
    "    train_loss /= len(trainloader.dataset)\n",
    "    test_loss /= len(valloader.dataset)\n",
    "    accuracy /= len(valloader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    print(f'Saving model for Epoch {epoch}')\n",
    "    torch.save(model.state_dict(), f'./models/model_{epoch}.pt')\n",
    "    \n",
    "    if accuracy > better_accuracy:\n",
    "        better_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), './models/model_best.pt')\n",
    "        print(f\"Saving improved Model for Epoch {epoch}\")\n",
    "    else:\n",
    "        print(\"Model is not improved for this time\")\n",
    "    \n",
    "    if scheduler is None:\n",
    "        print(\"No Schedular found. LR will not change\")\n",
    "    else:\n",
    "        if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step(test_loss)\n",
    "        else:\n",
    "            scheduler.step()\n",
    "    \n",
    "    b = datetime.datetime.now().replace(microsecond=0)    \n",
    "    print(f\"[Epoch: {epoch}/{EPOCHS}] Time Taken: {b-a} training loss: {train_loss} validation loss: {test_loss}, accuracy: {accuracy}\")\n",
    "    \n",
    "print(\"End of training!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe701488e50>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAArm0lEQVR4nO3deZhcVZ3/8fe3lt63pLuz7xuQhCRATICwupAACu4CCoo6GRwYd0fH34wbOqPjisM2GUQYQRAVFRVBZF8k0CEJWQghCySdpJPO0vtaVef3x6nu9JpukuquVNXn9Tz1VNe9t2+dm+VT537vuafMOYeIiKS+QLIbICIiiaFAFxFJEwp0EZE0oUAXEUkTCnQRkTQRStYbl5WVuSlTpiTr7UVEUtKqVav2O+fK+1qXtECfMmUKFRUVyXp7EZGUZGZv9LdOJRcRkTShQBcRSRMKdBGRNKFAFxFJEwp0EZE0MWCgm9ntZrbPzNb3s/7DZvZy/PGcmc1PfDNFRGQgg+mh3wEsO8L67cC5zrl5wPXAigS0S0RE3qQBA9059xRw8Ajrn3POHYq/fB6YkKC29WlTVR0/ePhVDjW2DeXbiIiknETX0D8B/KW/lWa23MwqzKyiurr6qN7g9f2N3Pj4FvbUthxtG0VE0lLCAt3MzscH+pf728Y5t8I5t9A5t7C8vM87VwdUnJsFQE2zeugiIl0l5NZ/M5sH3AZc6Jw7kIh99qc4NwxAbVP7UL6NiEjKOeYeuplNAu4HrnTObT72Jh1ZSV480JsV6CIiXQ3YQzeze4DzgDIzqwS+DoQBnHO3Al8DSoGbzQwg4pxbOFQN7gj0GgW6iEg3Awa6c+7yAdZ/Evhkwlo0gNxwkHDQqFHJRUSkm5S7U9TMKM7NUslFRKSHlAt08GWXWo1yERHpJiUDvTg3rJKLiEgPKRnoJblhlVxERHpIyUAvzlMPXUSkp9QM9Nwwdeqhi4h0k5KBXpKbRX1rhPZoLNlNERE5bqRmoMdvLlIvXUTksJQM9M75XBToIiKdUjPQdfu/iEgvKRnoJZpxUUSkl5QMdJVcRER6S8lAL8mLf8lFk27/FxHpkJKBXpTjJ4lUDV1E5LCUDPRQMEBhdkglFxGRLlIy0MGPdNFFURGRw1I30HPDKrmIiHSRsoHu50RXoIuIdEjdQM/N0igXEZEuUjbQizQnuohINykb6B0lF+dcspsiInJcSN1Azw3THnU0tUWT3RQRkeNCygZ6x+3/GukiIuKlbKB3zImusegiIl7KBnpxbnw+l2aNdBERgUEEupndbmb7zGx9P+vNzH5qZlvM7GUzOzXxzeytWFPoioh0M5ge+h3AsiOsvxCYGX8sB2459mYNrLPkohq6iAgwiEB3zj0FHDzCJpcC/+e854ESMxubqAb2p0TfWiQi0k0iaujjgZ1dXlfGl/ViZsvNrMLMKqqrq4/pTXPDQcJBo0YlFxERIDGBbn0s6/NuH+fcCufcQufcwvLy8mN7UzOKc7NUchERiUtEoFcCE7u8ngDsTsB+B+TvFtUoFxERSEygPwBcFR/tcjpQ65zbk4D9DqhY87mIiHQKDbSBmd0DnAeUmVkl8HUgDOCcuxV4ELgI2AI0AVcPVWN7KskNU1XXMlxvJyJyXBsw0J1zlw+w3gHXJqxFb0JxXphNVfXJeGsRkeNOyt4pCr7kUqeSi4gIkOKBXpKbRX1rhPZoLNlNERFJutQO9PjNReqli4ikeKB3zueiQBcRSfFA1+3/IiKdUjvQNeOiiEinlA70EpVcREQ6pXag58W/5KJJt/+LiKR0oBfl+PuiVEMXEUnxQA8FAxRmh1RyEREhxQMd/EgXXRQVEUmHQM8Nq+QiIkIaBLqfE12BLiKS+oGem6VRLiIipEGgF+lLLkREgDQI9I6Si5+WXUQkc6V+oOeGaY86mtqiyW6KiEhSpXygd8znopEuIpLpUj7QO+ZE11h0Ecl0KR/oxbnx+VyaNdJFRDJbGgS6eugiIpAGgd5ZclENXUQyXNoEui6KikimS/lAzw0HCQdNPXQRyXgpH+hmRnFuFjWqoYtIhhtUoJvZMjN71cy2mNlX+lhfbGZ/NLO1ZrbBzK5OfFP75+8W1SgXEclsAwa6mQWBm4ALgdnA5WY2u8dm1wIbnXPzgfOAH5pZVoLb2q9izeciIjKoHvoiYItzbptzrg24F7i0xzYOKDQzAwqAg0AkoS09gpLcsEouIpLxBhPo44GdXV5Xxpd1dSNwErAbWAd8xjkX67kjM1tuZhVmVlFdXX2UTe6tWIEuIjKoQLc+lvWc2nApsAYYBywAbjSzol6/5NwK59xC59zC8vLyN9nU/hXnhalTyUVEMtxgAr0SmNjl9QR8T7yrq4H7nbcF2A6cmJgmDqwkN4v61gjt0V4nBSIiGWMwgf4iMNPMpsYvdF4GPNBjmx3A2wDMbDRwArAtkQ09kuLcEIB66SKS0UIDbeCci5jZdcDDQBC43Tm3wcyuia+/FbgeuMPM1uFLNF92zu0fwnZ3U5LnB9TUNrdTWpA9XG8rInJcGTDQAZxzDwIP9lh2a5efdwMXJLZpg1es2/9FRFL/TlHQjIsiIpAmgV6SqxkXRUTSI9DjNfSaJt3+LyKZKzUD3Tn/iCvK8ZcCVEMXkUyWeoG+8QH4zwlQ80bnolAwQGF2SCUXEcloqRfoeaXQ1gAHtnZbXJwX1kVREcloqRfopTP8c89Azw2r5CIiGS31Ar1gFGQVwIEt3Rb7OdEV6CKSuVIv0M2gdHrvQM/N0igXEcloqRfo4MsuB7uXXIr0JRcikuFSN9BrdkCktXNRR8nFuZ4z+4qIZIbUDXQXg0Ovdy4qyQ3THnU0tUWT1y4RkSRKzUAfOd0/d6mjd8znopEuIpKpUjPQS6f55y6BXpKnCbpEJLOlZqDnjoC8sm5j0Ytz4/O5NGuki4hkptQMdPB19G6Brh66iGS2FA707mPRywv9NxXtqmlOVotERJIqtQO9oQpa6wEf6BNH5vLi6weT3DARkeRI4UDvPafLoimlvLD9oMaii0hGSv1A73LH6OJpIznU1M6WfQ1JapSISPKkbqCP7Bi62CXQp44EYOV2lV1EJPOkbqCHc6FoQrcLo5NG5jG6KFuBLiIZKXUDHXqNdDEzFk0t5YXtB1RHF5GMk+KBPsMHepfwXjx1JHvrWtlxsCmJDRMRGX6pH+gttdB0uMSiOrqIZKpBBbqZLTOzV81si5l9pZ9tzjOzNWa2wcyeTGwz+1Hae5KuGaMKGJmfxQsKdBHJMAMGupkFgZuAC4HZwOVmNrvHNiXAzcAlzrk5wAcS39Q+dI5F715Hf8uUEazcfmBYmiAicrwYTA99EbDFObfNOdcG3Atc2mObK4D7nXM7AJxz+xLbzH6UTIJAqNfX0S2eWsrOg83s1jQAIpJBBhPo44GdXV5Xxpd1NQsYYWZPmNkqM7uqrx2Z2XIzqzCziurq6qNrcVfBMIyY0uvr6BbF6+iaBkBEMslgAt36WNZzTGAIOA24GFgK/LuZzer1S86tcM4tdM4tLC8vf9ON7VOPWRcBThpbRGF2SBdGRSSjDCbQK4GJXV5PAHb3sc1DzrlG59x+4ClgfmKaOICR032gx2Kdi4IBY+GUEbowKiIZZTCB/iIw08ymmlkWcBnwQI9t/gCcbWYhM8sDFgOvJLap/SidDpFmqO/+GbN4Wilb9jWwv6G1n18UEUkvAwa6cy4CXAc8jA/p+5xzG8zsGjO7Jr7NK8BDwMvAC8Btzrn1Q9fsLvqYdRG61NHVSxeRDBEazEbOuQeBB3ssu7XH6+8D309c0wap69DFaed2Lp47rpjccJCV2w9y4cljh71ZIiLDLbXvFAUoHAvhvF499KxQgFMnl6iOLiIZI/UDPRDwU+n2GIsO/gsvXqmq0/eMikhGSP1Ah16zLnZYPG0kzkHFG+qli0j6S5NAnwE1b0C0e098wcQSsoIBlV1EJCOkT6DHIlCzo9vinHCQ+ROLdYORiGSE9Aj0kb1nXeywaOpI1u+qpbE1MsyNEhEZXukR6H3Muthh8dRSIjHHSzsODXOjRESGV3oEet5IyCnpM9BPnTyCYMB4buubmE43FoPmmoQ1T0RkOKRHoJv1OUkXQEF2iHNmlvGrF3fS3BYd3P6e+j78ZJ5CXURSSnoEOvQb6ADXnj+Dg41t3Pvijj7Xd9PWBCtvgdZaeKXnlDUJ9Mof4dmfDt3+RSTjpFGgT4e6Sh/IPSycMpJFU0ey4qlttEViffxyF2vvgeZDkF0Ma381NG2NxeDhr8Jj10Nb49C8h4hknPQKdICD2/pcfe35M9hT28LvV+/qfx+xGDx/C4w7Bc68Dt54Bmp29r/90Xr9aT/EMtoGbzyX+P2LSEZKo0CPj3TZs7bP1efMLGPu+CJueXIr0VjP7+eI2/IIHHgNzrgOTo5/Leq6+xLf1jV3+zOAUA5sfSzx+xeRjJQ+gT5qtn888jWo29NrtZlx7Xkz2L6/kQfX9V4PwN9vhKLxMPtSGDkVJp7uyy6unw+Ao9FSCxv/ACe/HyafqUAXkYRJn0APhuEDd0J7M/z2ExDtfSPR0jljmF6ez02Pb8H1DOmqdbD9KVi03O8LYP6HYP+r/fb6j8r630KkBU75CEx/K1RvgtojlIFERAYpfQIdoHwWvPPH8Maz8MR/9FodCBifOm8Gm6rqefzVfd1X/v1mPw3vaR89vGz2uyGYBS8nsOyy+m5/JjHuFB/oANseT9z+RSRjpVegg+9Vn3oVPP1DeO1vvVZfumAc40tyufGxLr30+ipY92vfa84dcXjjvJEw8wK/ro8e/5u27xXYVeHfx8wHe8FolV1EJCHSL9ABLvwvGDUHfre8VzkjHAxwzbnTeGlHDc9vi0/a9eJtfnKvxdf03te8D0HjPtj+xLG3a/VdEAj5fYIP9elvhW1PdPuSaxE5TkQjsOlB+OWH4GcXwMtH0bmLtvtrZ3V7/L0yVeuGrMw6qK+gSznhXPjgnbDiPF9P/+ifIHj4UD+wcCI3PLqFm5/YwhmT8uDFn8EJFx0e+tjVrKWQEx+TPuPtR9+maDu8/CuYtQzyyw4vn/5WP/a96mUYt+Do9y8iiVOzA176Baz+BdTvgYIxkF0I93/S3z9y5j/7M+1wbvffa22ArY/Cpj/D1sf9PS2xPr5gZ8ln4R3fTHiz0zPQAcpmwrtu8IH+2PXd/vBywkE+efZUvvuXTex84udMbD4IZ/xT3/sJZcOc9/g6emsDZBccXXte+ys0VsMpV3ZfPu08/7z1MQW6ZI62Jnj1QX8tqa+O1FByDup2Q/NBf2Nfx6O9CVrrYfPDsCVerp3xdrj4hzBzKVgANv8FnvkxPPhFeOK7cPo1MPs9/rrdpj/7s+1oK+SOhJnvgKJxEM73wZ+V53/OyoOyWUNyaOkb6OCHBr7+NDz7Ez/me/r5/h9QKJsPL57ELY9vJrjyZtzY+djkJf3vZ95lsOoO/xc2/0NH15bVd/l6ec9efsEoGHOyD/SzP390+xZJtkgrNO6H4vFH3i7a7nu9T3wPGqrAgr4Eec4X+w/2WNR3iCp+Dvs3Q16pP8vNK4P8Uv+cVwq5Jf5sOqfYT9aXU+w7ZNWv+jLH3vX+ueplXwLpT+FYOOdLcOqVUDKp+7oTL/Zn828854P9sW/7B/ht3/IJv83E07tVBYZLegc6wLLv+rtHn/yufwSzYNwpFE5czM+mRRi3bSfPlP8TZ5n1v4+Ji/1f1sv39h3o7S1+OOKUs2DE5N7r6/f6T/0z/7nvv+Rp5/s7VNsaISv/6I81k0Tb4d4rYPRceNvX/PWIdNJ4AFbe6s8Ip78NRs859mN0zpcAat7wd0DX7PDXhyYv8e9xNAHUsM+XLCt+5s9AR83x93HMeTeUn3B4u1gMNv7eh9/BrT7wLvlv36Ot+JkvR86/zAf7yGmH9/3S/8GqO6F2hw/aSWf4Y6jbBXtehqb9/o7rwQjn+T/HOe/1zwWj/f+3jkc4zz/nl0Mg2P9+zGDKEv+oWgevP+v/7yfi7+gYWa/x2MNk4cKFrqKiYvjesKEadq6Enc/DjpWwezXE2jkYLOPs1p/wm2vP5aSxRf3//mPf9iNnPv8KFI7xy5zzQf63b/p/cOE8Hy6Llnf/B/HsDf6Gp+sqfCmop62Pwy/eDVf8GmZdkNDDTltPff9wz2jZd+H0TyW3PYkSi8Kqn8Oj18d7kfH/nwWj/Qf/jLf554LyQe4vBmvugpX/A4deh7aG7ustCC4K+aNg3gdh/uUwZu7A+93zsu+ErP+ND9RZy3zYbn4Idjzv211+oh/6O+pEeOYnsGcNlJ8Eb/+6374j/Oqr/PqK2/3ghPmXQ6QZNj7g689Tz/U93xMuOnyPSAfnfJmk6YD/8+r5aG/2Pf8xJ/sPiiMFdYows1XOuYV9rsuYQO+pvQV2r+agFbP0F7spzg3zwHVLyMvqp5ey/zW4cSFc8B0/z8vOF/wEW5Uv+n8s53zJX0TZ8giMXwiX3gijTvL/4G5a7E8HP/HX/tvyvclw2tVw4XeH7JDTRvWrcOtZ/j94LOJLYZf9Ek68aOjes6PuemCLnx7iwDbfoy2d6aedKJ3hywA9e2gdveLG/f6GsvITfBmgLztWwoNf8L2+KWfDRd/3ZYOtj/uS3LbHfXABTD4LzvqcD/j+eoV7N8CfPu87MeNOPXymWTLRPxdPhKwCX85Ye48P41gExsyDBVf4bwKLtBx+tLf4OvOWv/lSZjgfTvkwLPpHKJtx+H3r9viZSjf+IT5XkfPvdf5XfXmlv1Ct2+PLoxU/9yXSBVfAwo/7+0ukkwJ9AM+8tp8rb1/JB0+byPfeP6//DVec7/9Bj5oNG+73V77f9jV/qhgI+v+8634Nf/my7zWc8yV/KnbHRf708tSr+t/3L94LtZVw3QuJP8B0EovC7ct8qF77oj9FvuMiH/JXxy+yJUprvT+zqnzRB3h7l5kxQ7k+/LqOYMgp9sGeU+zLD437/XOsyzC3QNifmo8/1Yfs+FP9vQ+PXg9rf+mnnrjg2/5CfM+gjsWgaq2/v2LVz33ZYcw8f+3lpEsOB2VbIzz5Pfj7TZBd5Pe34IqBywGNB3yPe80vfW+6P8WTYPFyf4E/t+TI+6yv8h9QU8/p/4Osp5Y63xPvOYJEgAQEupktA24AgsBtzrk+u5Fm9hbgeeBDzrnfHGmfx1OgA3z/4U3c9PhWfnr5KVwyf1zfGz1/Kzz0Zf+fecmn4cxP9z3qpXG/D/X1v/E1+0AIvrjZD3vqz3M3wl//H3xuAxRPSMxBpaOOv4P3rDh8PaN+L9z2Nl9X/4dHE/Pn11ANd78Pqtb7i+mlM30vtHSG/7lwLLgY1O6M99rjj/2v+Q+CglG+x55f7ssZHXXZPWth90uwew201h1+v0DYX2M5+wuDG0kVafN152d/4t+3dAYs+YwfXfHQV3y7TrkS3vEtf4Pcm7V/C7TU+J5yKAfCOf7ffSjbf4im2zWLFHJMgW5mQWAz8A6gEngRuNw5t7GP7R4BWoDbUy3Q26MxLlvxPK9W1fPgp89mUmle743amvxol9mXDnw1H+DVh/zwphMvhgu/d+Rt926EW86AS270V9elt0Ovw81n+LOeK+7rHip7N8LtS30p4eMPHfnDcyAHt8Nd7/UlgA/e6e9FSLRYzF8c3PWSv2h/8ge6ly0GvZ+oL288/SM/egP8GeQ7fwyTTk9sm+W4cKyBfgbwDefc0vjrfwVwzv1nj+0+C7QDbwH+lGqBDlB5qImLbniaqWX5/PqaM8kKJehGWucG7tE4Bz880V85f//tiXnfNysa8afxJZMG1wNr2OdHYoTzfOiNnjt0PTfn/IXjygq4dmXfvfAtj8LdH/A3a11+r69xR9v9MdXsiM9B3+7LE/mlfb/Pnpfh7vf7YXgf/jVMXDQ0x5NozvkbWhr2+Q+HnhcPJW0cKdAHM05pPND1Wx4qgcU93mA88B7grfhA768hy4HlAJMmTepvs6SZMCKP/3r/PK656yX+66FN/Ns7Zydmx4MJuY5pADY/5HtvgWGelWH3anjg076XN3ExnPsvfihbX21vb4bnb4anf+zryi7mb94qGu/nvpm1zNdMs/o4y+mLcz6odzznLwaOO6X3+6652w9xu/iH/ZdUZrzNr//TZ+HWJb6WXLfLt6+rv/yLP2s69SqYet7hP+vtT/uhkNmF8PEH/OiMVGF2bHcyS1oYTKD3lUY9u/U/Ab7snIvaEcLLObcCWAG+hz7INg6rZXPHcuXpk7ntme3kZQX53DtmcaRjSqjp5/sLY1Vru1/caz4EL9zm17U2xC/GdXm4mA+od1zf9zj4I2lrhMf/wwd0fjmc/UVYey/c9T4/WufcL/s73sz8B83638Cj3/I12hMu9jXa7AJ47RF47WF/UXhVfJTClLP8ELvpb/Ujfnr+OTZU+7H9q+/y0wh3GDkN5r7PP0ad5C+sPfxVP176tI8f+XgWXu2H5m16EMbOh5LJ8ZEd8Udbo/9wWHsPbPidX3bKlX4o6p+/ACOmwpX36zqGpKSElFzMbDuHg78MaAKWO+d+399+j8eSS4dINMZXf7eO+yoquXzRJL797rkEA8MQ6g374Acz/ciZs7/ga7h/v9HX7dsafDiOmOIvsgZC/iJbIHQ4pGJRf7H2rM8N7gal1/4Gf/qcH0N/2tXw9m/4UQuRNr+/p3/k141d4KcVfukX/oLe2Pl++ObUs3vvM9Lqh6ptftiXAPZv9ssLxvgPrOlv9UPl1tx9eJjchEWH54ff9jis+40fFudi/kaVUDbs2wifei5xt4lHWmHTn/yNK9ue8MsmLIIrfnV0FxFFhsmx1tBD+IuibwN24S+KXuGc29DP9neQojX0rpxzfP/hV7n5ia0snTOaGy47hZzwMNyUcOtZfs6IsfN9TzkW9T3VJZ858g0ftbvgb9/wX5lXOM7PXXPyB3r3iptr/MW452/xvemyWX7Om8ln9t5ntN234ekf+AuSheP8h828Dw2+JFRb2WUc9RN+/gzwt2vPv8z3jvsqbdTv9XcWrv+tvyGsY/z/UDi43X+AzH3/4MtEIkmSiGGLF+HLKkH8CJbvmNk1AM65W3tsewdpEOgdbn9mO9/600YWTx3J/350IUU5Q3yx6ZGv+TtLQzm+13rGdf7r8AZrx0o/rG/3at/jnPF2OLTdT9t5cOvhG1MCYX+b9VmfG3h8cDQCu1b5G6iOJfA6xlE3HYAp50Aoa3C/11IHOUe4i1ckg+jGomP0hzW7+MJ9a5k5upA7r34Lo4pyhu7NGvbB+vth7nv9WOajEYv5evvfvunn6iga7+vSpdP93X+l030ZZTBDL0XkuKJAT4CnNldzzV2rKC3I4rar3sIJY45hnPNwibb7h8oIImnjSIGent9YNATOmVXOPf9wOs1tMd5907M8sHZ3sps0sGBYYS6SQRTob8L8iSX8+dNnMWdcEZ++ZzXf+uNG2qP66jgROT4o0N+k0UU53LP8dD525hRuf3Y7V/zv8+yra0l2s0REFOhHIxwM8I1L5nDDZQtYv6uOi//7GV7YfjDZzRKRDKdAPwaXLhjP769dQkF2iMv/93nufO51knWRWUREgX6MThhTyB+uW8L5J5Tz9Qc28NXfraMtorq6iAw/BXoCFOWEWXHlQq49fzr3vLCTj9y2kgMNrclulohkGAV6ggQCxpeWnsgNly1gbWUNl9z4LBt31w38iyIiCaJAT7BLF4zn19ecQTTmeP+tz/HQ+j3JbpKIZAgF+hCYN6GEB65bwqzRhVxz10vc/sz2ZDdJRDKAAn2IjCrK4d7lp7N0zmi+/eeNPPPa/mQ3SUTSnAJ9COWEg/zogwuYXl7Ap+9dze6a5mQ3SUTSmAJ9iOVnh7j1ytNoi8T41N0v0RqJJrtJIpKmFOjDYHp5AT/4wDzW7qzhW3/cmOzmiEiaUqAPk2Vzx/KP507j7pU7+O2qymQ3R0TSkAJ9GH3pghM4Y1opX/3dOjbsrk12c0QkzSjQh1EoGOC/rziFEXlZfOqul6htak92k0QkjSjQh1lZQTY3ffhU9tQ287n71hCNaTIvEUkMBXoSnDZ5BF9/1xwe27SP/3p4U7KbIyJpIpTsBmSqj5w+mVer6vmfJ7cxc1Qh7z9tQrKbJCIpTj30JPrau2azZEYpX71/Have0BdkiMixUaAnUTgY4KYrTmVcSQ7/+ItVVB5qSnaTRCSFKdCTrCQvi9s++hZaIzE+eWcFja2RZDdJRFLUoALdzJaZ2atmtsXMvtLH+g+b2cvxx3NmNj/xTU1fM0YVcNMVp7J5bz2f+9UaYhr5IiJHYcBAN7MgcBNwITAbuNzMZvfYbDtwrnNuHnA9sCLRDU1358wq59/fOZu/btzLD/76arKbIyIpaDCjXBYBW5xz2wDM7F7gUqBzUhLn3HNdtn8e0JCNo/CxM6eweW8DNz+xlWDA+Pw7ZmFmyW6WiKSIwQT6eGBnl9eVwOIjbP8J4C99rTCz5cBygEmTJg2yiZnDzLj+0jnEYo7/fmwL1fWtfPvdcwkFdalDRAY2mEDvq4vYZ5HXzM7HB/pZfa13zq0gXo5ZuHChCsV9CAUDfPd9J1NemM2Nj2/hYGMbP738FHLCwWQ3TUSOc4Pp+lUCE7u8ngDs7rmRmc0DbgMudc4dSEzzMpOZ8cWlJ/CNd83mkVf2ctXtL1DbrHlfROTIBhPoLwIzzWyqmWUBlwEPdN3AzCYB9wNXOuc2J76ZmeljS6Zyw2WnsHrHIT70P39nb11LspskIsexAQPdORcBrgMeBl4B7nPObTCza8zsmvhmXwNKgZvNbI2ZVQxZizPMJfPH8fOPLWLnwSbed8tzvLTjULKbJCLHKXMuOaXshQsXuooK5f5grausZfkvKqiqa+EjiyfzpWUnUJQTTnazRGSYmdkq59zCvtZp+ESKOHlCMY98/lw+duYU7l75Bm//4ZM8uG4PyfpAFpHjjwI9hRRkh/j6u+bw+2uXUF6YzT/d/RKfuLOCnQc1B4yIKNBT0rwJJfzh2iX828Un8fy2A1zw46f4+bPbNWWASIZToKeoUDDAJ8+exiOfP5fF00byzT9u5KrbX2BPbXOymyYiSaJAT3HjS3L5+cfewnfeM5dVbxxi6Y+f4o9re90mICIZQIGeBsyMDy+ezIOfOZtp5QX88z2r+cy9q/Ul1CIZRl9Bl0amluXzm2vO4OYntnLDo6/xwvaDXL7Iz5kTiTmisRiRmCMWc4wryeXyRZM0pYBIGtE49DS1dmcNX/j1Wrbsa+hcFgyYf5jR3B5lSmke37hkDuedMCqJLRWRN+NI49AV6GnMOUdbNEYoECBgdJuK96nN1XzjgQ1s29/I0jmj+fd3zmbCiLwktlZEBkM3FmUoMyM7FCQYsF7zqp8zq5y/fPZsvrT0BJ7cXM3bf/QkNz2+hdZINEmtFZFjpR66sKummev/uJGHNlQxviSXxVNHcuLYQk4cU8SJYwspL8jWF22IHCdUcpFBeXJzNXc+9zobd9dR1WVmx9L8LE4aW8Q5s8pYOmcMk0vzk9hKkcymQJc37VBjG5uq6tlUVccre+p4ubKWTVX1AJw4ppAL5oxh6ZzRzB5bpN67yDBSoEtC7DzYxMMbqvjrhr28+MZBnIOJI3M5Y1opJ48vZs74Yk4aU0RuloZCigwVBbokXHV9K397ZS+PbNzL6h2HOBS/iSkYMGaUFzBnfBEnjilkalkBU8vymDgyj+yQgl7kWCnQZUg559hT28L6XbX+sbuOdbtqqa5v7dwmYDCuJJepZfmUFWTT2BqhviVCQ2uE+pZ2GlojtEViTCsv4KSxRZwUvyh7wphCinM177tIBwW6JEVtUzvbDzTy+v5Gtscfrx9o5EBDG4U5IQqyQ/45J0xhToiAwZZ9Dbyyp77bd6iOL8ll7vgi5k0oYd6EYuaNL6E4r++Qb26LsreuhfZojNKCbEpywwQCqvFL+jhSoOvWfxkyxXlhFuSVsGBiyZv6Pecce+taeaWqjk176tm4p451lTU8vGFv5zZTSvOYN6GEcDDA3rqWzkddS6TbvoIBY0ReFmUFWZQWZDEyP5sReWFKcsOU5GUxIt8/l+ZnMXNUoer/ktIU6HLcMTPGFOcwpjiH87tMS1Db1M66XbWsrazh5coaKl4/CMCoohymlxdw5vRSRhXlMLooh3DQONDQxsHGNg40trK/oY0DDa2sO1TDoaZ26lra6XlyGjCYOaqQueOLmTu+iJPHFzN7XBGRmGNfXQt761qpqm1hb30L++paaWqL4BzEHDgcOIg5R3FumPkTSzhl0gimlOYlbBRQLOaIOkc05ggHAwR15iE9qOQiGSkac9Q1t3OoqY1DTe1U17ewMV77X7erjv0NrUf8/cLsEPnZoW5TKgQCYBgHGlppbPN33JbkhVkw0Z+lnDS2iKxQgID5+XQCBoGAEXOO6vpWdtU0s7ummd01LeyuaWZPbQvNbdHOEO+rDUW5Yf/I8T8X5oTIzwqRlxUkL/6cmxWkIDtEUW6I4twwxfHfKc4Nkx0KUt/STlVtC1V1Leypben8uTAnxPSyAqaW5zOtLJ+R+Vm9Ppxa2qNU17eyr76F1kiMqWX5jCnK0VDWIaSSi0gPwYAxIj+LEflZncuWzR0LHC75rNtVy6Y9deSEg4wqymZ0vPc/uiibvKz+/+tEY44t+xpYveMQq3fUsGZnDU9ufq3XGUFfRuSFGVeSy4QReSyaOpK8rBDBAP4DIGCEAv65tT1GXUs7tc3t1DVHqGtuZ+fBJupbIjS1RWhqi9IaiQ34fuGg0R7t3bCR+Vk0tERoix7eR1FOiGnlBeSGg+yrb2FffSv1PUpcAHlZQaaV5zO9vIBpZQVMLs0jGP/gAn8W03lm4xwu/mfu/EkOzkEoaOSGg+SEg/HnADlhP41FJOrnKIpEY7RHHe2xGEEzppTmM35E7nF/5lJV20LA/JlloqmHLjIM6lva2b6/kUjM4Zwj5nzwd4TcqMIcxpXkHPGD4s2KxhxNbRGa26I0tEaobW7vfNTFn+tbI4zMy2JMcQ5ji3MZW5zDqKJsskNBojHHrkPNbN3fwPbqRrbtb2BbdSOtkRijCrMZVZhNeWE2owpzKC/KJhwIsP1AI1v3NbBtv3/eVTO836CVFQwwqTSPqWX+rGLiyDwCZp1TR0djrvMZINQxA2n8wzIYCBAKGOGQEQoECAcDhINGOBgg5hz1LZH4o73zuS3qGFecw8SReUwY4T+MRxVmEwgYdS3trKusZc3OGtburGFtZQ1761r51HnT+fKyE4/qGDXKRUSSorktGg91B1hniSpgvjxlRvxhGPGfMdqjMVojUZrbYrREojS3RWlpj3ZePwiHAoQDRjjkA7gtEuONA01s29/I9v0NfkTV/qZuZxiJFjD/xe2hYICDjW3d1mUFA5QWZFFV19J5Zja1LJ/5E4qZP7GEJTPKmDW68KjeVyUXEUmK3KwgM0YVDMt7LZ5W2u11NOY674UIBa2zNx4KBAgEDm/T8aUvXXvw7ZEYkViMtogjEovRHo0BRlFOiMKcMAU5IfKzgp3XCvwHVxM7DzVTeaiZykNNVNe1+hCf6IfbluRlMdQU6CKSloIBP1pqOPgPrkJmjDq6XneiDGo+dDNbZmavmtkWM/tKH+vNzH4aX/+ymZ2a+KaKiMiRDBjoZhYEbgIuBGYDl5vZ7B6bXQjMjD+WA7ckuJ0iIjKAwfTQFwFbnHPbnHNtwL3ApT22uRT4P+c9D5SY2dgEt1VERI5gMIE+HtjZ5XVlfNmb3QYzW25mFWZWUV1d/WbbKiIiRzCYQO9rlH7PsY6D2Qbn3Arn3ELn3MLy8vLBtE9ERAZpMIFeCUzs8noCsPsothERkSE0mEB/EZhpZlPNLAu4DHigxzYPAFfFR7ucDtQ65/YkuK0iInIEA45Dd85FzOw64GEgCNzunNtgZtfE198KPAhcBGwBmoCrh67JIiLSl6Td+m9m1cAbR/nrZcD+BDYnlWTqseu4M4uOu3+TnXN9XoRMWqAfCzOr6G8ug3SXqceu484sOu6jM6g7RUVE5PinQBcRSROpGugrkt2AJMrUY9dxZxYd91FIyRq6iIj0lqo9dBER6UGBLiKSJlIu0Aeamz1dmNntZrbPzNZ3WTbSzB4xs9fizyOS2cahYGYTzexxM3vFzDaY2Wfiy9P62M0sx8xeMLO18eP+Znx5Wh93BzMLmtlqM/tT/HXaH7eZvW5m68xsjZlVxJcd03GnVKAPcm72dHEHsKzHsq8AjzrnZgKPxl+nmwjwBefcScDpwLXxv+N0P/ZW4K3OufnAAmBZfBqNdD/uDp8BXunyOlOO+3zn3IIuY8+P6bhTKtAZ3NzsacE59xRwsMfiS4E74z/fCbx7ONs0HJxze5xzL8V/rsf/Jx9Pmh97/LsEGuIvw/GHI82PG8DMJgAXA7d1WZz2x92PYzruVAv0Qc27nsZGd0x6Fn8eleT2DCkzmwKcAqwkA449XnZYA+wDHnHOZcRxAz8B/gWIdVmWCcftgL+a2SozWx5fdkzHnWpfEj2oedcl9ZlZAfBb4LPOubqOb1dPZ865KLDAzEqA35nZ3CQ3aciZ2TuBfc65VWZ2XpKbM9yWOOd2m9ko4BEz23SsO0y1Hnqmz7u+t+Or/eLP+5LcniFhZmF8mN/tnLs/vjgjjh3AOVcDPIG/hpLux70EuMTMXseXUN9qZneR/seNc253/Hkf8Dt8SfmYjjvVAn0wc7OnsweAj8Z//ijwhyS2ZUiY74r/DHjFOfejLqvS+tjNrDzeM8fMcoG3A5tI8+N2zv2rc26Cc24K/v/zY865j5Dmx21m+WZW2PEzcAGwnmM87pS7U9TMLsLX3DrmZv9Ocls0NMzsHuA8/HSae4GvA78H7gMmATuADzjnel44TWlmdhbwNLCOwzXVr+Lr6Gl77GY2D38RLIjvaN3nnPuWmZWSxsfdVbzk8kXn3DvT/bjNbBq+Vw6+9P1L59x3jvW4Uy7QRUSkb6lWchERkX4o0EVE0oQCXUQkTSjQRUTShAJdRCRNKNBFRNKEAl1EJE38f2kRP4QnwwVQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe701468110>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.2013692372360698,\n",
       " 0.6681859752533665,\n",
       " 0.5170481585133188,\n",
       " 0.44004949677361155,\n",
       " 0.3899884643885681,\n",
       " 0.35656985064304486,\n",
       " 0.32786819278892193,\n",
       " 0.2976758241437952,\n",
       " 0.25051305294036863,\n",
       " 0.20629041658220132,\n",
       " 0.17291969527219053,\n",
       " 0.14989667852461036,\n",
       " 0.12432453124228372,\n",
       " 0.12485679112649532,\n",
       " 0.10277324024741406,\n",
       " 0.09614711146551203,\n",
       " 0.08449002946966037,\n",
       " 0.07727001379664909,\n",
       " 0.07193581331965722,\n",
       " 0.07399537640900519,\n",
       " 0.06736539613040715,\n",
       " 0.0597816073304057,\n",
       " 0.06354865197763009,\n",
       " 0.06041733950621631,\n",
       " 0.057720054183976854,\n",
       " 0.050405248592318784,\n",
       " 0.0541527497277084,\n",
       " 0.05436308285678028,\n",
       " 0.04638804024757463,\n",
       " 0.046053474128720386,\n",
       " 0.050334797421401595,\n",
       " 0.05077923217994401,\n",
       " 0.04842571902882768,\n",
       " 0.046795275946371985,\n",
       " 0.04435833481262322,\n",
       " 0.04836652926125564,\n",
       " 0.04282430770900572,\n",
       " 0.04639148095559358,\n",
       " 0.04070249887443244,\n",
       " 0.0409174836242729,\n",
       " 0.04109910714856887,\n",
       " 0.039738003960228106,\n",
       " 0.04053229297917344,\n",
       " 0.035071148501408765,\n",
       " 0.03567046892552469,\n",
       " 0.035150338200797056,\n",
       " 0.0343600013805789,\n",
       " 0.036481507785149615,\n",
       " 0.031843169657372085,\n",
       " 0.03960771000097605]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1\n",
       "0  0.jpg  0\n",
       "1  1.jpg  0\n",
       "2  2.jpg  0\n",
       "3  3.jpg  0\n",
       "4  4.jpg  0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the Datafarme\n",
    "test_data = pd.read_csv('./dataset/test_challenge.csv')\n",
    "test_data = test_data.replace({'1': classes_to_idx})\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CENTER_CROP_FIVE:\n",
    "    testset = SatelliteDataset(dataroot='./dataset/test/', X_array=test_data['0'].values, Y_array=test_data['1'].values, \n",
    "                               transform=transforms.Compose([transforms.Resize(256),\n",
    "                                                             transforms.FiveCrop(IMAGE_SIZE),\n",
    "                                                             transforms.Lambda(lambda crops: torch.stack([\n",
    "                                                                 transforms.Normalize([0.4728, 0.4762, 0.4692],\n",
    "                                                                                      [0.2558, 0.2532, 0.2457])(\n",
    "                                                                     transforms.ToTensor()(crop)) for crop in crops]))\n",
    "                                                            ]))\n",
    "\n",
    "else:\n",
    "    testset = SatelliteDataset(dataroot='./dataset/test/', X_array=test_data['0'].values, Y_array=test_data['1'].values, \n",
    "                               transform=transforms.Compose([transforms.Resize(CROP_SIZE),\n",
    "                                                             transforms.CenterCrop(IMAGE_SIZE),\n",
    "                                                             transforms.ToTensor(),\n",
    "                                                             transforms.Normalize([0.4728, 0.4762, 0.4692],\n",
    "                                                                                  [0.2558, 0.2532, 0.2457])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsetloader = DataLoader(testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testsetloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infarence_and_save(epoch):\n",
    "    model.load_state_dict(torch.load(f'./models/model_{epoch}.pt'))\n",
    "\n",
    "    y_test_pred = np.empty(0)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in testsetloader:\n",
    "            x = data['image'].to(device)\n",
    "            if CENTER_CROP_FIVE:\n",
    "                bs, ncrops, c, h, w = x.size()\n",
    "                out = torch.exp(model(x.view(-1, c, h, w)))\n",
    "                out, _ = out.argmax(1).view(bs, ncrops).median(1)\n",
    "                y_test_pred = np.append(y_test_pred, out.cpu().numpy())\n",
    "            else:\n",
    "                out = model(x)\n",
    "                out = torch.exp(out).argmax(1)\n",
    "                y_test_pred = np.append(y_test_pred, out.cpu().numpy())\n",
    "\n",
    "    y_test_pred.shape\n",
    "\n",
    "    d = {'0': test_data['0'].values, '1': y_test_pred.astype(int)}\n",
    "    pd.DataFrame(d).replace({'1': idx_to_classes}).to_csv(f'./output_{epoch}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working for epoch 1\n",
      "Working for epoch 2\n",
      "Working for epoch 3\n",
      "Working for epoch 4\n",
      "Working for epoch 5\n",
      "Working for epoch 6\n",
      "Working for epoch 7\n",
      "Working for epoch 8\n",
      "Working for epoch 9\n",
      "Working for epoch 10\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 31):\n",
    "    print(f\"Working for epoch {i}\")\n",
    "    infarence_and_save(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.empty(0)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in testsetloader:\n",
    "        x = data['image'].to(device)\n",
    "        bs, ncrops, c, h, w = x.size()\n",
    "        out = torch.exp(model(x.view(-1, c, h, w)))\n",
    "        out = out.view(bs, ncrops, -1)\n",
    "        print(out.argmax(1))\n",
    "        print(out.shape)\n",
    "        print(out.mean(1).argmax(1))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.mnightly-2021-01-20-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:mnightly-2021-01-20-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
