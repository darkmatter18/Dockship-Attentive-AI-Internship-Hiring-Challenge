{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Training](#Training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet18, densenet121\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CROP_SIZE = 256\n",
    "IMAGE_SIZE = 224\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "LR = 0.0001\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>Adhered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>Adhered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>Concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>Concrete</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>Plastic &amp; fabric</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                 1\n",
       "0  0.jpg           Adhered\n",
       "1  1.jpg           Adhered\n",
       "2  2.jpg          Concrete\n",
       "3  3.jpg          Concrete\n",
       "4  4.jpg  Plastic & fabric"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the Datafarme\n",
    "data = pd.read_csv('./dataset/train_challenge.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Classes\n",
    "CLASSES = ['Adhered', 'Ballasted', 'Concrete', 'Plastic & fabric', 'Shingle', 'Steel']\n",
    "\n",
    "classes_to_idx = {cls: idx for idx, cls in enumerate(CLASSES)}\n",
    "idx_to_classes = {idx: cls for idx, cls in enumerate(CLASSES)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1\n",
       "0  0.jpg  0\n",
       "1  1.jpg  0\n",
       "2  2.jpg  2\n",
       "3  3.jpg  2\n",
       "4  4.jpg  3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace '1' column with classes_to_idx dict\n",
    "data = data.replace({'1': classes_to_idx})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make X and Y from dataframe\n",
    "X = data['0'].values\n",
    "Y = data['1'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 6915\n",
      "Validation size: 1729\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split into train, validation and test sets\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "print(f\"Train size: {len(X_train)}\\nValidation size: {len(X_val)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Torch Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatelliteDataset(Dataset):\n",
    "    def __init__(self, dataroot: str, X_array: np.array, Y_array: np.array, transform = None, target_transform = None):\n",
    "        self.dataroot = dataroot\n",
    "        self.X_array = X_array\n",
    "        self.Y_array = Y_array\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_name = self.X_array[index]\n",
    "        img = Image.open(os.path.join(self.dataroot, file_name)).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        label = np.array(self.Y_array[index])\n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "        else:\n",
    "            label = torch.from_numpy(label)\n",
    "\n",
    "        return {'image': img, 'label': label, 'image_name': file_name}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SatelliteDataset(dataroot='./dataset/train/', X_array=X_train, Y_array=y_train, \n",
    "                                 transform=transforms.Compose([\n",
    "                                                               transforms.Resize(CROP_SIZE),\n",
    "                                                               transforms.RandomHorizontalFlip(),\n",
    "                                                               transforms.RandomCrop(IMAGE_SIZE),\n",
    "                                                               transforms.ToTensor(),\n",
    "                                                               transforms.Normalize([0.4728, 0.4762, 0.4692],\n",
    "                                                                                    [0.2558, 0.2532, 0.2457])]))\n",
    "\n",
    "val_dataset = SatelliteDataset(dataroot='./dataset/train/', X_array=X_val, Y_array=y_val, \n",
    "                               transform=transforms.Compose([transforms.Resize(CROP_SIZE),\n",
    "                                                             transforms.CenterCrop(IMAGE_SIZE),\n",
    "                                                             transforms.ToTensor(),\n",
    "                                                             transforms.Normalize([0.4728, 0.4762, 0.4692],\n",
    "                                                                                  [0.2558, 0.2532, 0.2457])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Tesla T4 for Training\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Using {torch.cuda.get_device_name()} for Training\")\n",
    "else:\n",
    "    print(\"Using CPU for Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResnetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResnetModel, self).__init__()\n",
    "        r = resnet18(pretrained=True)\n",
    "        fc = nn.Linear(r.fc.in_features, len(CLASSES))\n",
    "        r.fc = fc\n",
    "        self.model = r\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DensenetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DensenetModel, self).__init__()\n",
    "        m = densenet121(pretrained=True)\n",
    "        fc = nn.Linear(m.classifier.in_features, len(CLASSES))\n",
    "        m.classifier = fc\n",
    "        self.model = m\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DensenetModel(\n",
       "  (model): DenseNet(\n",
       "    (features): Sequential(\n",
       "      (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu0): ReLU(inplace=True)\n",
       "      (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (denseblock1): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition1): _Transition(\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock2): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition2): _Transition(\n",
       "        (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock3): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer13): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer14): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer15): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer16): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer17): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer18): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer19): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer20): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer21): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer22): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer23): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer24): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (transition3): _Transition(\n",
       "        (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      )\n",
       "      (denseblock4): _DenseBlock(\n",
       "        (denselayer1): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer2): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer3): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer4): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer5): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer6): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer7): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer8): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer9): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer10): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer11): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer12): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer13): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer14): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer15): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (denselayer16): _DenseLayer(\n",
       "          (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU(inplace=True)\n",
       "          (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "      (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (classifier): Linear(in_features=1024, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DensenetModel()\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "criterion = nn.NLLLoss().cuda() if torch.cuda.is_available() else nn.NLLLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-04.\n"
     ]
    }
   ],
   "source": [
    "scheduler = lr_scheduler.StepLR(optimizer, 4, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model for Epoch 1\n",
      "Saving improved Model for Epoch 1\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "[Epoch: 1/20] training loss: 0.7945073786500736 validation loss: 0.45877220561688825, accuracy: 0.8390455531453362\n",
      "Saving model for Epoch 2\n",
      "Saving improved Model for Epoch 2\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "[Epoch: 2/20] training loss: 0.46269320681400256 validation loss: 0.3482492091383351, accuracy: 0.8806941431670282\n",
      "Saving model for Epoch 3\n",
      "Saving improved Model for Epoch 3\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "[Epoch: 3/20] training loss: 0.3663473050446072 validation loss: 0.2522932712443911, accuracy: 0.9114967462039045\n",
      "Saving model for Epoch 4\n",
      "Saving improved Model for Epoch 4\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "[Epoch: 4/20] training loss: 0.3146201147347021 validation loss: 0.21289677971398926, accuracy: 0.930296456977585\n",
      "Saving model for Epoch 5\n",
      "Saving improved Model for Epoch 5\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "[Epoch: 5/20] training loss: 0.2304206154437834 validation loss: 0.1611638568918169, accuracy: 0.9472161966738973\n",
      "Saving model for Epoch 6\n",
      "Saving improved Model for Epoch 6\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "[Epoch: 6/20] training loss: 0.2049198129258118 validation loss: 0.14643533334987197, accuracy: 0.954591467823572\n",
      "Saving model for Epoch 7\n",
      "Saving improved Model for Epoch 7\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "[Epoch: 7/20] training loss: 0.1957917685536311 validation loss: 0.13644478843316424, accuracy: 0.9587852494577006\n",
      "Saving model for Epoch 8\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "[Epoch: 8/20] training loss: 0.18114042789799875 validation loss: 0.13209945236373793, accuracy: 0.9586406362979031\n",
      "Saving model for Epoch 9\n",
      "Saving improved Model for Epoch 9\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "[Epoch: 9/20] training loss: 0.173561657466323 validation loss: 0.12877639514526765, accuracy: 0.9609544468546638\n",
      "Saving model for Epoch 10\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "[Epoch: 10/20] training loss: 0.16650612192660763 validation loss: 0.13384017372101178, accuracy: 0.959942154736081\n",
      "Saving model for Epoch 11\n",
      "Saving improved Model for Epoch 11\n",
      "Adjusting learning rate of group 0 to 1.0000e-06.\n",
      "[Epoch: 11/20] training loss: 0.1625238409787093 validation loss: 0.12387197082424543, accuracy: 0.9625451916124367\n",
      "Saving model for Epoch 12\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "[Epoch: 12/20] training loss: 0.1658298738273864 validation loss: 0.12739203150235304, accuracy: 0.9606652205350686\n",
      "Saving model for Epoch 13\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "[Epoch: 13/20] training loss: 0.16942866098510123 validation loss: 0.12276703609572488, accuracy: 0.9619667389732466\n",
      "Saving model for Epoch 14\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "[Epoch: 14/20] training loss: 0.16320738884218344 validation loss: 0.131784281851111, accuracy: 0.9595083152566883\n",
      "Saving model for Epoch 15\n",
      "Saving improved Model for Epoch 15\n",
      "Adjusting learning rate of group 0 to 1.0000e-07.\n",
      "[Epoch: 15/20] training loss: 0.16332468783088291 validation loss: 0.12137348273107734, accuracy: 0.9644251626898048\n",
      "Saving model for Epoch 16\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "[Epoch: 16/20] training loss: 0.16150057531747797 validation loss: 0.12266431024496054, accuracy: 0.9635574837310196\n",
      "Saving model for Epoch 17\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "[Epoch: 17/20] training loss: 0.16506201357231223 validation loss: 0.12433891545493622, accuracy: 0.9629790310918294\n",
      "Saving model for Epoch 18\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "[Epoch: 18/20] training loss: 0.16567492381610993 validation loss: 0.12392256600985645, accuracy: 0.9631236442516269\n",
      "Saving model for Epoch 19\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 1.0000e-08.\n",
      "[Epoch: 19/20] training loss: 0.16453821157857462 validation loss: 0.12896836265781525, accuracy: 0.9605206073752711\n",
      "Saving model for Epoch 20\n",
      "Model is not improved for this time\n",
      "Adjusting learning rate of group 0 to 1.0000e-09.\n",
      "[Epoch: 20/20] training loss: 0.16503025964818308 validation loss: 0.12344384062725482, accuracy: 0.9628344179320318\n",
      "End of training!!\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "test_losses = []\n",
    "accuracies = []\n",
    "better_accuracy = 0.0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    #Training\n",
    "    train_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for data in trainloader:\n",
    "        x = data['image'].to(device)\n",
    "        y = data['label'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * x.size(0)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in valloader:\n",
    "            x = data['image'].to(device)\n",
    "            y = data['label'].to(device)\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            test_loss += loss.item() * x.size(0)\n",
    "            accuracy += accuracy_score(y.cpu().numpy(), torch.exp(out).argmax(1).cpu().numpy()) * x.size(0)\n",
    "        \n",
    "    train_loss /= len(trainloader.dataset)\n",
    "    test_loss /= len(valloader.dataset)\n",
    "    accuracy /= len(valloader.dataset)\n",
    "    train_losses.append(train_loss)\n",
    "    test_losses.append(test_loss)\n",
    "    accuracies.append(accuracy)\n",
    "    \n",
    "    print(f'Saving model for Epoch {epoch}')\n",
    "    torch.save(model.state_dict(), f'./models/model_{epoch}.pt')\n",
    "    \n",
    "    if accuracy > better_accuracy:\n",
    "        better_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), './models/model_best.pt')\n",
    "        print(f\"Saving improved Model for Epoch {epoch}\")\n",
    "    else:\n",
    "        print(\"Model is not improved for this time\")\n",
    "    \n",
    "    if scheduler is None:\n",
    "        print(\"No Schedular found. LR will not change\")\n",
    "    else:\n",
    "        if isinstance(scheduler, lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step(test_loss)\n",
    "        else:\n",
    "            scheduler.step()\n",
    "        \n",
    "    print(f\"[Epoch: {epoch}/{EPOCHS}] training loss: {train_loss} validation loss: {test_loss}, accuracy: {accuracy}\")\n",
    "    \n",
    "print(\"End of training!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa80c060690>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(test_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa80c01cfd0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.empty(0)\n",
    "y_pred = np.empty(0)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        x = data['image'].to(device)\n",
    "        y = data['label'].to(device)\n",
    "        out = model(x)\n",
    "        out = torch.exp(out).argmax(1)\n",
    "        y_true = np.append(y_true, y.cpu().numpy())\n",
    "        y_pred = np.append(y_pred, out.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true, y_pred, target_names=CLASSES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1\n",
       "0  0.jpg  0\n",
       "1  1.jpg  0\n",
       "2  2.jpg  0\n",
       "3  3.jpg  0\n",
       "4  4.jpg  0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the Datafarme\n",
    "test_data = pd.read_csv('./dataset/test_challenge.csv')\n",
    "test_data = test_data.replace({'1': classes_to_idx})\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENTER_CROP_FIVE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CENTER_CROP_FIVE:\n",
    "    testset = SatelliteDataset(dataroot='./dataset/test/', X_array=test_data['0'].values, Y_array=test_data['1'].values, \n",
    "                               transform=transforms.Compose([transforms.Resize(256),\n",
    "                                                             transforms.FiveCrop(IMAGE_SIZE),\n",
    "                                                             transforms.Lambda(lambda crops: torch.stack([\n",
    "                                                                 transforms.Normalize([0.4728, 0.4762, 0.4692],\n",
    "                                                                                      [0.2558, 0.2532, 0.2457])(\n",
    "                                                                     transforms.ToTensor()(crop)) for crop in crops]))\n",
    "                                                            ]))\n",
    "\n",
    "else:\n",
    "    testset = SatelliteDataset(dataroot='./dataset/test/', X_array=test_data['0'].values, Y_array=test_data['1'].values, \n",
    "                               transform=transforms.Compose([transforms.Resize(CROP_SIZE),\n",
    "                                                             transforms.CenterCrop(IMAGE_SIZE),\n",
    "                                                             transforms.ToTensor(),\n",
    "                                                             transforms.Normalize([0.4728, 0.4762, 0.4692],\n",
    "                                                                                  [0.2558, 0.2532, 0.2457])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsetloader = DataLoader(testset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testsetloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infarence_and_save(epoch):\n",
    "    model.load_state_dict(torch.load(f'./models/model_{epoch}.pt'))\n",
    "\n",
    "    y_test_pred = np.empty(0)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in testsetloader:\n",
    "            x = data['image'].to(device)\n",
    "            if CENTER_CROP_FIVE:\n",
    "                bs, ncrops, c, h, w = x.size()\n",
    "                out = torch.exp(model(x.view(-1, c, h, w)))\n",
    "                out, _ = out.argmax(1).view(bs, ncrops).median(1)\n",
    "                y_test_pred = np.append(y_test_pred, out.cpu().numpy())\n",
    "            else:\n",
    "                out = model(x)\n",
    "                out = torch.exp(out).argmax(1)\n",
    "                y_test_pred = np.append(y_test_pred, out.cpu().numpy())\n",
    "\n",
    "    y_test_pred.shape\n",
    "\n",
    "    d = {'0': test_data['0'].values, '1': y_test_pred.astype(int)}\n",
    "    pd.DataFrame(d).replace({'1': idx_to_classes}).to_csv(f'./output_{epoch}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working for epoch 1\n",
      "Working for epoch 2\n",
      "Working for epoch 3\n",
      "Working for epoch 4\n",
      "Working for epoch 5\n",
      "Working for epoch 6\n",
      "Working for epoch 7\n",
      "Working for epoch 8\n",
      "Working for epoch 9\n",
      "Working for epoch 10\n",
      "Working for epoch 11\n",
      "Working for epoch 12\n",
      "Working for epoch 13\n",
      "Working for epoch 14\n",
      "Working for epoch 15\n",
      "Working for epoch 16\n",
      "Working for epoch 17\n",
      "Working for epoch 18\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 21):\n",
    "    print(f\"Working for epoch {i}\")\n",
    "    infarence_and_save(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 4, 4, 4, 4],\n",
      "        [3, 1, 1, 2, 0, 4],\n",
      "        [4, 0, 1, 1, 1, 1],\n",
      "        [1, 2, 3, 0, 1, 1],\n",
      "        [3, 0, 1, 3, 3, 2],\n",
      "        [3, 0, 2, 2, 2, 1],\n",
      "        [0, 2, 3, 2, 2, 0],\n",
      "        [2, 4, 4, 4, 3, 1],\n",
      "        [0, 0, 0, 3, 1, 0],\n",
      "        [2, 1, 2, 3, 2, 0],\n",
      "        [2, 2, 3, 3, 1, 4],\n",
      "        [3, 0, 3, 3, 4, 0],\n",
      "        [3, 2, 2, 3, 3, 0],\n",
      "        [0, 0, 0, 1, 0, 2],\n",
      "        [1, 4, 4, 2, 0, 1],\n",
      "        [2, 2, 2, 2, 1, 0],\n",
      "        [2, 0, 0, 1, 1, 1],\n",
      "        [2, 3, 2, 1, 3, 4],\n",
      "        [0, 0, 0, 3, 0, 0],\n",
      "        [3, 3, 3, 3, 4, 3],\n",
      "        [1, 1, 2, 4, 1, 1],\n",
      "        [1, 2, 4, 3, 4, 4],\n",
      "        [2, 2, 0, 4, 4, 3],\n",
      "        [3, 0, 2, 3, 4, 3],\n",
      "        [3, 1, 1, 3, 1, 2],\n",
      "        [0, 0, 0, 1, 1, 4],\n",
      "        [4, 1, 1, 2, 3, 2],\n",
      "        [1, 4, 4, 4, 4, 4],\n",
      "        [2, 3, 1, 0, 1, 1],\n",
      "        [2, 2, 3, 3, 3, 2],\n",
      "        [3, 1, 4, 2, 0, 4],\n",
      "        [2, 1, 2, 3, 4, 1]], device='cuda:0')\n",
      "torch.Size([32, 5, 6])\n",
      "tensor([1, 5, 0, 2, 5, 1, 2, 5, 3, 5, 4, 4, 5, 5, 4, 5, 1, 5, 3, 4, 2, 0, 0, 4,\n",
      "        5, 5, 5, 0, 0, 0, 5, 4], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = np.empty(0)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in testsetloader:\n",
    "        x = data['image'].to(device)\n",
    "        bs, ncrops, c, h, w = x.size()\n",
    "        out = torch.exp(model(x.view(-1, c, h, w)))\n",
    "        out = out.view(bs, ncrops, -1)\n",
    "        print(out.argmax(1))\n",
    "        print(out.shape)\n",
    "        print(out.mean(1).argmax(1))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-7.mnightly-2021-01-20-debian-10-test",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-7:mnightly-2021-01-20-debian-10-test"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
